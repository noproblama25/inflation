{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNyt88mrQOhDLW9oK+WJyQ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noproblama25/inflation/blob/main/DataSourcing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Investigating inflation trends in the Netherlands"
      ],
      "metadata": {
        "id": "nuv_b6q0gYvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Inflation (target)"
      ],
      "metadata": {
        "id": "0bSKsoTMgbM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Data Sourcing"
      ],
      "metadata": {
        "id": "TwUzWseCgfvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source (ECB): https://data.ecb.europa.eu/data/datasets/ICP/ICP.M.BE.N.000000.4.ANR"
      ],
      "metadata": {
        "id": "hm9Ye3qRgsci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install eurostat"
      ],
      "metadata": {
        "id": "3075YsZCZrDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vutlu0uCZdia"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import eurostat\n",
        "from datetime import datetime\n",
        "import requests\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "from io import StringIO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COUNTRIES = ['NL', 'BE', 'DE']\n",
        "START_YEAR = 1997\n",
        "END_YEAR = 2025\n",
        "\n",
        "def filter_dates(df, start_year=1997, end_year=2025):\n",
        "    \"\"\"Filter dataframe to date range\"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # Find time column\n",
        "    time_col = None\n",
        "    for col in ['TIME_PERIOD', 'time', 'freq\\\\TIME_PERIOD']:\n",
        "        if col in df.columns:\n",
        "            time_col = col\n",
        "            break\n",
        "\n",
        "    if time_col is None:\n",
        "        return df\n",
        "\n",
        "    # Extract year from time column\n",
        "    df['year'] = pd.to_datetime(df[time_col], errors='coerce').dt.year\n",
        "    filtered = df[(df['year'] >= start_year) & (df['year'] <= end_year)].copy()\n",
        "    filtered.drop('year', axis=1, inplace=True)\n",
        "\n",
        "    return filtered\n",
        "\n",
        "def get_all_eurostat_data():\n",
        "    \"\"\"Extract Eurostat data 1997-2025 for NL, BE, DE\"\"\"\n",
        "\n",
        "    datasets = {}\n",
        "\n",
        "    # CATEGORY 1: HICP Components\n",
        "    try:\n",
        "        df = eurostat.get_data_df('prc_hicp_midx',\n",
        "                                  filter_pars={'geo': COUNTRIES,\n",
        "                                              'coicop': ['CP00', 'NRG', 'FOOD', 'SERV', 'IGD_NNRG']})\n",
        "        datasets['hicp_components'] = filter_dates(df, START_YEAR, END_YEAR)\n",
        "    except:\n",
        "        datasets['hicp_components'] = pd.DataFrame()\n",
        "\n",
        "    # CATEGORY 2: Labor Market\n",
        "    try:\n",
        "        df = eurostat.get_data_df('une_rt_m',\n",
        "                                  filter_pars={'geo': COUNTRIES, 's_adj': 'SA',\n",
        "                                              'age': 'TOTAL', 'sex': 'T'})\n",
        "        datasets['unemployment'] = filter_dates(df, START_YEAR, END_YEAR)\n",
        "    except:\n",
        "        datasets['unemployment'] = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = eurostat.get_data_df('earn_mw_cur', filter_pars={'geo': COUNTRIES})\n",
        "        datasets['minimum_wage'] = filter_dates(df, START_YEAR, END_YEAR)\n",
        "    except:\n",
        "        datasets['minimum_wage'] = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = eurostat.get_data_df('lc_lci_r2_q',\n",
        "                                  filter_pars={'geo': COUNTRIES, 's_adj': 'SCA',\n",
        "                                              'nace_r2': 'B-S'})\n",
        "        datasets['labor_costs'] = filter_dates(df, START_YEAR, END_YEAR)\n",
        "    except:\n",
        "        datasets['labor_costs'] = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = eurostat.get_data_df('lc_ulc_r2_q',\n",
        "                                  filter_pars={'geo': COUNTRIES, 's_adj': 'SCA',\n",
        "                                              'nace_r2': 'B-S'})\n",
        "        datasets['unit_labor_costs'] = filter_dates(df, START_YEAR, END_YEAR)\n",
        "    except:\n",
        "        datasets['unit_labor_costs'] = pd.DataFrame()\n",
        "\n",
        "    # CATEGORY 4: Economic Growth\n",
        "    try:\n",
        "        df = eurostat.get_data_df('namq_10_gdp',\n",
        "                                  filter_pars={'geo': COUNTRIES, 's_adj': 'SCA',\n",
        "                                              'na_item': 'B1GQ', 'unit': 'CLV_PCH_PRE'})\n",
        "        datasets['gdp_growth'] = filter_dates(df, START_YEAR, END_YEAR)\n",
        "    except:\n",
        "        datasets['gdp_growth'] = pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = eurostat.get_data_df('nama_10_lp_ulc',\n",
        "                                  filter_pars={'geo': COUNTRIES, 'na_item': 'LPR_HW',\n",
        "                                              'unit': 'PCH_PRE'})\n",
        "        datasets['productivity'] = filter_dates(df, START_YEAR, END_YEAR)\n",
        "    except:\n",
        "        datasets['productivity'] = pd.DataFrame()\n",
        "\n",
        "    return datasets\n",
        "\n",
        "# Execute\n",
        "data = get_all_eurostat_data()\n",
        "\n",
        "# Access dataframes\n",
        "hicp = data['hicp_components']\n",
        "unemployment = data['unemployment']\n",
        "min_wage = data['minimum_wage']\n",
        "gdp = data['gdp_growth']\n"
      ],
      "metadata": {
        "id": "ZryBmyWDhkxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdp"
      ],
      "metadata": {
        "id": "Pn7zUNPO-Xmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ecb_inflation_data(countries=['NL', 'BE', 'DE'], start_year=1997):\n",
        "    \"\"\"Get HICP inflation from ECB Data Portal API\"\"\"\n",
        "\n",
        "    components = {\n",
        "        '000000': 'Total',\n",
        "        'NRG': 'Energy',\n",
        "        'FOOD': 'Food',\n",
        "        'SERV': 'Services',\n",
        "        'IGD_NNRG': 'Goods_excl_energy'\n",
        "    }\n",
        "\n",
        "    all_data = []\n",
        "\n",
        "    for country in countries:\n",
        "        for code, label in components.items():\n",
        "            # Correct ECB SDMX API format\n",
        "            url = f\"https://data-api.ecb.europa.eu/service/data/ICP/M.{country}.N.{code}.4.ANR\"\n",
        "\n",
        "            params = {\n",
        "                'startPeriod': f'{start_year}-01',\n",
        "                'format': 'csvdata'\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url, params=params, timeout=30)\n",
        "                if response.status_code == 200:\n",
        "                    df = pd.read_csv(StringIO(response.text))\n",
        "                    df['country'] = country\n",
        "                    df['component'] = label\n",
        "                    all_data.append(df)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if not all_data:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    result = pd.concat(all_data, ignore_index=True)\n",
        "    return result\n",
        "\n",
        "# Execute\n",
        "ecb_inflation = get_ecb_inflation_data(countries=['NL', 'BE', 'DE'], start_year=1997)\n",
        "\n"
      ],
      "metadata": {
        "id": "sv2dzsbPicRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load VAT.csv and tobacco_excise_cleaned\n",
        "\n",
        "vat = pd.read_csv('VAT.csv')\n",
        "tobacco_excise = pd.read_csv('tobacco_excise_cleaned.csv')"
      ],
      "metadata": {
        "id": "4jJhRtobhWAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Data Cleaning"
      ],
      "metadata": {
        "id": "AcV-wxKHhCb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check and display the headers of the various dataframes\n",
        "# print dataframe name next to it\n",
        "\n",
        "print(ecb_inflation.head())\n",
        "print(hicp.head())\n",
        "print(unemployment.head())\n",
        "print(min_wage.head())\n",
        "print(gdp.head())\n",
        "print(vat.head())\n",
        "print(tobacco_excise.head())\n"
      ],
      "metadata": {
        "id": "VQS9U2aPg8Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanup of hicp dataframe"
      ],
      "metadata": {
        "id": "ScubdX0IubG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop rows where coicop = 'IGD_NNRG' from dataframe\n",
        "hicp = hicp[hicp['coicop'] != 'IGD_NNRG']\n",
        "\n",
        "# Identify period columns\n",
        "# Corrected column name: 'geo\\TIME_PERIOD' contains the country codes\n",
        "id_cols = ['coicop', 'geo\\TIME_PERIOD', 'freq', 'unit'] # Add 'freq' and 'unit' to id_cols\n",
        "period_cols = [col for col in hicp.columns if col not in id_cols]\n",
        "\n",
        "df_hicp = hicp.melt(\n",
        "    id_vars=['coicop', 'geo\\TIME_PERIOD'], # Only these should be identifiers for melting\n",
        "    value_vars=period_cols,\n",
        "    var_name='PERIOD',\n",
        "    value_name='VALUES'\n",
        ")\n",
        "\n",
        "# Rename the 'geo\\TIME_PERIOD' column to 'geo' for easier access\n",
        "df_hicp = df_hicp.rename(columns={'geo\\TIME_PERIOD': 'geo'})\n",
        "\n",
        "# Optionally convert PERIOD to datetime\n",
        "df_hicp['PERIOD'] = pd.to_datetime(df_hicp['PERIOD'], format='%Y-%m')\n",
        "\n",
        "# remove all records with PERIOD < 1997-01-01\n",
        "df_hicp = df_hicp[df_hicp['PERIOD'] >= '1997-01-01']\n",
        "\n",
        "df_hicp.head()"
      ],
      "metadata": {
        "id": "mw_h4rp6nq5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "265dbf79"
      },
      "source": [
        "print(\"Unique values in hicp['coicop']:\")\n",
        "display(df_hicp['coicop'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanup of unemployment dataframe"
      ],
      "metadata": {
        "id": "uqyqej2qu4G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert date columns similar to earleir with hicp\n",
        "\n",
        "# Identify identifier columns specific to the unemployment dataframe\n",
        "# Based on `unemployment.head()` output, these are 'freq', 's_adj', 'age', 'unit', 'sex', 'geo\\TIME_PERIOD'\n",
        "unempl_id_cols = ['freq', 's_adj', 'age', 'unit', 'sex', 'geo\\TIME_PERIOD']\n",
        "\n",
        "# Identify period columns for unemployment dataframe\n",
        "unempl_period_cols = [col for col in unemployment.columns if col not in unempl_id_cols]\n",
        "\n",
        "df_unempl = unemployment.melt(\n",
        "    id_vars=unempl_id_cols,\n",
        "    value_vars=unempl_period_cols,\n",
        "    var_name='PERIOD',\n",
        "    value_name='VALUES'\n",
        ")\n",
        "\n",
        "# Rename the 'geo\\TIME_PERIOD' column to 'geo' for easier access\n",
        "df_unempl = df_unempl.rename(columns={'geo\\TIME_PERIOD': 'geo'})\n",
        "\n",
        "# Optionally convert PERIOD to datetime\n",
        "df_unempl['PERIOD'] = pd.to_datetime(df_unempl['PERIOD'], format='%Y-%m', errors='coerce')\n",
        "\n",
        "# Remove any rows where PERIOD conversion failed (if any) or VALUES are NaN\n",
        "df_unempl = df_unempl.dropna(subset=['PERIOD', 'VALUES'])\n",
        "\n",
        "# Remove any rows with date < 1997-01-01\n",
        "df_unempl = df_unempl[df_unempl['PERIOD'] >= '1997-01-01']\n",
        "\n",
        "# Remove any rows with UNIT <> PC_ACT\n",
        "df_unempl = df_unempl[df_unempl['unit'] == 'PC_ACT']\n",
        "\n",
        "# drop all columns except PERIOD, VALUES, geo\n",
        "df_unempl = df_unempl[['PERIOD', 'VALUES', 'geo']]\n",
        "\n",
        "df_unempl.head()"
      ],
      "metadata": {
        "id": "jUqOviXhv3Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanup of minimum wage"
      ],
      "metadata": {
        "id": "GcL-6OCyy0ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_wage"
      ],
      "metadata": {
        "id": "9Q8zbbrdy7gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Identify semi-annual columns (all columns with year pattern)\n",
        "semi_annual_cols = [col for col in min_wage.columns if isinstance(col, str) and '-S' in col]\n",
        "\n",
        "# Step 2: Create monthly dataframe\n",
        "monthly_data = []\n",
        "\n",
        "for idx, row in min_wage.iterrows():\n",
        "    new_row = {\n",
        "        'freq': row['freq'],\n",
        "        'currency': row['currency'],\n",
        "        'geo': row['geo\\TIME_PERIOD']  # Note: using the actual column name\n",
        "    }\n",
        "\n",
        "    # Process each semi-annual period\n",
        "    for col in semi_annual_cols:\n",
        "        year = int(col.split('-')[0])\n",
        "        semester = col.split('-')[1]\n",
        "\n",
        "        # S1 = Jan-Jun, S2 = Jul-Dec\n",
        "        months = range(1, 7) if semester == 'S1' else range(7, 13)\n",
        "\n",
        "        # Fill all 6 months with semi-annual value\n",
        "        for month in months:\n",
        "            date_str = f\"{year}-{month:02d}\"\n",
        "            new_row[date_str] = row[col]\n",
        "\n",
        "    monthly_data.append(new_row)\n",
        "\n",
        "df_minwage = pd.DataFrame(monthly_data)\n",
        "\n",
        "# Step 3: Backfill 1997-1998 using 1999-01 value\n",
        "for year in [1997, 1998]:\n",
        "    for month in range(1, 13):\n",
        "        date_str = f\"{year}-{month:02d}\"\n",
        "        df_minwage[date_str] = df_minwage['1999-01']\n",
        "\n",
        "# Step 4: Reorder columns chronologically\n",
        "date_cols = sorted([col for col in df_minwage.columns if '-' in col and col not in ['freq', 'currency', 'geo']])\n",
        "df_minwage = df_minwage[['freq', 'currency', 'geo'] + date_cols]\n",
        "\n",
        "# only keep rows with currency = EUR\n",
        "df_minwage = df_minwage[df_minwage['currency'] == 'EUR']\n",
        "\n",
        "# Melt the df_minwage to long format\n",
        "id_vars_minwage = ['freq', 'currency', 'geo']\n",
        "value_vars_minwage = [col for col in df_minwage.columns if col not in id_vars_minwage]\n",
        "\n",
        "df_minwage_melted = df_minwage.melt(\n",
        "    id_vars=id_vars_minwage,\n",
        "    value_vars=value_vars_minwage,\n",
        "    var_name='PERIOD',\n",
        "    value_name='VALUES'\n",
        ")\n",
        "\n",
        "# Convert 'PERIOD' to datetime\n",
        "df_minwage_melted['PERIOD'] = pd.to_datetime(df_minwage_melted['PERIOD'], format='%Y-%m', errors='coerce')\n",
        "\n",
        "# Remove rows with NaN values in 'VALUES' (e.g., for Germany before 2015)\n",
        "df_minwage_melted.dropna(subset=['VALUES'], inplace=True)\n",
        "\n",
        "# Filter to date range 1997-01-01 onwards if not already handled\n",
        "df_minwage_melted = df_minwage_melted[df_minwage_melted['PERIOD'] >= '1997-01-01']\n",
        "\n",
        "# Divide VALUES by 174 which is monthly working hours\n",
        "df_minwage_melted['VALUES'] = df_minwage_melted['VALUES'] / 160\n",
        "\n",
        "print(f\"Shape of df_minwage_melted: {df_minwage_melted.shape}\")\n",
        "print(f\"Date range: {df_minwage_melted['PERIOD'].min().strftime('%Y-%m')} to {df_minwage_melted['PERIOD'].max().strftime('%Y-%m')}\")\n",
        "print(f\"\\nFirst few rows:\\n{df_minwage_melted.head()}\")"
      ],
      "metadata": {
        "id": "FLhJk7d20Ba6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanup of GDP dataframe"
      ],
      "metadata": {
        "id": "mnP0iARU3slJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdp"
      ],
      "metadata": {
        "id": "OoQzD2fN3wd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify identifier columns for the GDP dataframe\n",
        "gdp_id_cols = ['freq', 'unit', 's_adj', 'na_item', 'geo\\TIME_PERIOD']\n",
        "\n",
        "# Identify period columns for GDP dataframe\n",
        "gdp_period_cols = [col for col in gdp.columns if col not in gdp_id_cols]\n",
        "\n",
        "df_gdp = gdp.melt(\n",
        "    id_vars=gdp_id_cols,\n",
        "    value_vars=gdp_period_cols,\n",
        "    var_name='PERIOD',\n",
        "    value_name='VALUES'\n",
        ")\n",
        "\n",
        "# Rename the 'geo\\TIME_PERIOD' column to 'geo' for easier access\n",
        "df_gdp = df_gdp.rename(columns={'geo\\TIME_PERIOD': 'geo'})\n",
        "\n",
        "# Convert 'PERIOD' to datetime objects. Eurostat quarterly data uses YYYY-QX format.\n",
        "# We will convert it to the first day of the quarter.\n",
        "df_gdp['PERIOD'] = df_gdp['PERIOD'].str.replace(r'(Q1)', '-01-01', regex=True)\n",
        "df_gdp['PERIOD'] = df_gdp['PERIOD'].str.replace(r'(Q2)', '-04-01', regex=True)\n",
        "df_gdp['PERIOD'] = df_gdp['PERIOD'].str.replace(r'(Q3)', '-07-01', regex=True)\n",
        "df_gdp['PERIOD'] = df_gdp['PERIOD'].str.replace(r'(Q4)', '-10-01', regex=True)\n",
        "df_gdp['PERIOD'] = pd.to_datetime(df_gdp['PERIOD'], errors='coerce')\n",
        "\n",
        "# Remove any rows where PERIOD conversion failed (if any) or VALUES are NaN\n",
        "df_gdp = df_gdp.dropna(subset=['PERIOD', 'VALUES'])\n",
        "\n",
        "# Filter to date range 1997-01-01 onwards\n",
        "df_gdp = df_gdp[df_gdp['PERIOD'] >= '1997-01-01']\n",
        "\n",
        "print(f\"Shape of df_gdp: {df_gdp.shape}\")\n",
        "print(f\"Date range: {df_gdp['PERIOD'].min().strftime('%Y-%m')} to {df_gdp['PERIOD'].max().strftime('%Y-%m')}\")\n",
        "print(f\"\\nFirst few rows:\\n{df_gdp.head()}\")"
      ],
      "metadata": {
        "id": "GQZRCH3T5lJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop all columns except freq, geo, period and values\n",
        "df_gdp = df_gdp[['freq', 'geo', 'PERIOD', 'VALUES']]\n",
        "df_gdp"
      ],
      "metadata": {
        "id": "Y6ktwyI84JdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanup of VAT dataframe"
      ],
      "metadata": {
        "id": "ifkWc1E79zEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming dataframe from yearly times series to monthly by filling the months with yearly value\n",
        "vat_monthly = vat.copy()\n",
        "vat_monthly = vat_monthly.rename(columns={'Jaar': 'year'}) # Rename 'Jaar' to 'year'\n",
        "vat_monthly['month'] = 1 # Assume January for yearly data if no month is specified\n",
        "vat_monthly['year'] = vat_monthly['year'].astype(str)\n",
        "vat_monthly['month'] = vat_monthly['month'].astype(str)\n",
        "vat_monthly['date'] = vat_monthly['year'] + '-' + vat_monthly['month'] + '-01'\n",
        "vat_monthly['date'] = pd.to_datetime(vat_monthly['date'])\n",
        "vat_monthly = vat_monthly.set_index('date')\n",
        "vat_monthly = vat_monthly.resample('MS').ffill()\n",
        "vat_monthly = vat_monthly.reset_index()\n"
      ],
      "metadata": {
        "id": "msWhebLy92Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accijnsen cleanup"
      ],
      "metadata": {
        "id": "_aqhjzYu-0Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tobacco_excise"
      ],
      "metadata": {
        "id": "ijqU1c1t_JIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming dataframe from yearly times series to monthly by filling the months with yearly value\n",
        "tobacco_excise_monthly = tobacco_excise.copy()\n",
        "tobacco_excise_monthly = tobacco_excise_monthly.rename(columns={'Year': 'year'}) # Rename 'Year' to 'year'\n",
        "tobacco_excise_monthly['month'] = 1 # Assume January for yearly data if no month is specified\n",
        "tobacco_excise_monthly['year'] = tobacco_excise_monthly['year'].astype(str)\n",
        "tobacco_excise_monthly['month'] = tobacco_excise_monthly['month'].astype(str)\n",
        "tobacco_excise_monthly['date'] = tobacco_excise_monthly['year'] + '-' + tobacco_excise_monthly['month'] + '-01'\n",
        "tobacco_excise_monthly['date'] = pd.to_datetime(tobacco_excise_monthly['date'])\n",
        "tobacco_excise_monthly = tobacco_excise_monthly.set_index('date')\n",
        "tobacco_excise_monthly = tobacco_excise_monthly.resample('MS').ffill()\n",
        "tobacco_excise_monthly = tobacco_excise_monthly.reset_index()\n",
        "tobacco_excise_monthly.head()"
      ],
      "metadata": {
        "id": "SeiF8nRA_Xyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# backfill 1997, 19998, 1999 creating values using data from 2000\n",
        "\n",
        "# Get the tobacco excise values for the year 2000 (first month, as they are constant per year)\n",
        "# Ensure 'year' column is int for proper filtering\n",
        "tobacco_excise_monthly['year'] = tobacco_excise_monthly['year'].astype(int)\n",
        "excise_2000 = tobacco_excise_monthly[tobacco_excise_monthly['year'] == 2000].iloc[0]\n",
        "\n",
        "backfill_data = []\n",
        "for year_to_backfill in [1997, 1998, 1999]:\n",
        "    for month_num in range(1, 13): # For each month of the year\n",
        "        date_str = f\"{year_to_backfill}-{month_num:02d}-01\"\n",
        "        backfill_data.append({\n",
        "            'date': pd.to_datetime(date_str),\n",
        "            'year': year_to_backfill,\n",
        "            'NL': excise_2000['NL'],\n",
        "            'DE': excise_2000['DE'],\n",
        "            'BE': excise_2000['BE'],\n",
        "            'month': month_num\n",
        "        })\n",
        "\n",
        "df_backfill = pd.DataFrame(backfill_data)\n",
        "\n",
        "# Concatenate the backfilled data with the original monthly data\n",
        "tobacco_excise_monthly = pd.concat([df_backfill, tobacco_excise_monthly]).sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(f\"Shape of tobacco_excise_monthly after backfill: {tobacco_excise_monthly.shape}\")\n",
        "print(f\"Date range: {tobacco_excise_monthly['date'].min().strftime('%Y-%m')} to {tobacco_excise_monthly['date'].max().strftime('%Y-%m')}\")\n",
        "print(f\"\\nFirst few rows:\\n{tobacco_excise_monthly.head()}\")"
      ],
      "metadata": {
        "id": "XWFybX48_5OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tobacco_excise_monthly"
      ],
      "metadata": {
        "id": "TAmmFbJJAePr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs inflation figures"
      ],
      "metadata": {
        "id": "Dv9RSnoGgyqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inflation per country\n",
        "\n",
        "inflation_NL = ecb_inflation[ecb_inflation['country'] == 'NL']\n",
        "inflation_BE = ecb_inflation[ecb_inflation['country'] == 'BE']\n",
        "inflation_DE = ecb_inflation[ecb_inflation['country'] == 'DE']\n",
        "\n",
        "# transpose column OBS_VALUE to the serie per TIME_PERIOD\n",
        "\n",
        "NL_serie = inflation_NL.pivot(index='TIME_PERIOD', columns='component', values='OBS_VALUE')\n",
        "BE_serie = inflation_BE.pivot(index='TIME_PERIOD', columns='component', values='OBS_VALUE')\n",
        "DE_serie = inflation_DE.pivot(index='TIME_PERIOD', columns='component', values='OBS_VALUE')\n",
        "\n",
        "# combine countries series into a single dataframe\n",
        "\n",
        "inflation_all = pd.concat([NL_serie, BE_serie, DE_serie], axis=1)\n"
      ],
      "metadata": {
        "id": "B3-wPcCHvHL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot of inflation\n",
        "\n",
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Prepare the data for plotting\n",
        "# Filter ecb_inflation for the 'Total' component\n",
        "df_plot = ecb_inflation[ecb_inflation['component'] == 'Total'].copy()\n",
        "\n",
        "# Convert 'TIME_PERIOD' to datetime objects for proper plotting\n",
        "df_plot['TIME_PERIOD'] = pd.to_datetime(df_plot['TIME_PERIOD'])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=df_plot, x='TIME_PERIOD', y='OBS_VALUE', hue='country')\n",
        "plt.title('Inflation Trends Over Time by Country (Total HICP)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Inflation (%)')\n",
        "plt.grid(False)\n",
        "\n",
        "# Set the x-axis major locator and formatter\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(1)) # Show a tick every year\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) # Format the date as YYYY\n",
        "\n",
        "# Set the x-axis limits to match the data range\n",
        "ax.set_xlim(df_plot['TIME_PERIOD'].min(), df_plot['TIME_PERIOD'].max())\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SkmRbM8j0Erz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot series of component of dataframe df_hicp as a line\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define a mapping for coicop codes to more descriptive labels\n",
        "coicop_label_map = {\n",
        "    'CP00': 'Total HICP',\n",
        "    'NRG': 'Energy',\n",
        "    'FOOD': 'Food',\n",
        "    'SERV': 'Services'\n",
        "    # 'IGD_NNRG' was dropped earlier in data cleaning, so it's not included here\n",
        "}\n",
        "\n",
        "# Create a new column with descriptive coicop labels for plotting\n",
        "df_hicp_plot = df_hicp.copy()\n",
        "df_hicp_plot['coicop_label'] = df_hicp_plot['coicop'].map(coicop_label_map)\n",
        "\n",
        "# Create the FacetGrid\n",
        "g = sns.FacetGrid(\n",
        "    df_hicp_plot,\n",
        "    col='coicop_label',\n",
        "    col_wrap=2,\n",
        "    height=4,\n",
        "    aspect=1.2,\n",
        "    sharey=False,\n",
        "    hue='geo' # Pass hue to FacetGrid to define color mapping for all subplots\n",
        ")\n",
        "\n",
        "# Map the line plot to each facet\n",
        "g.map_dataframe(sns.lineplot, x='PERIOD', y='VALUES')\n",
        "\n",
        "# Set overall title for the plot\n",
        "g.fig.suptitle('Inflation Trends by Component and Country', y=1.02, fontsize=16)\n",
        "\n",
        "# Improve labels for each subplot\n",
        "for ax in g.axes.flat:\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel('Index Value')\n",
        "    ax.tick_params(axis='x', rotation=45) # Rotate x-axis labels\n",
        "\n",
        "    # Set the x-axis major locator and formatter for each subplot\n",
        "    ax.xaxis.set_major_locator(mdates.YearLocator(5)) # Show a tick every 5 years\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) # Format the date as YYYY\n",
        "\n",
        "    # Add a legend to each subplot\n",
        "    # This should now work correctly because map_dataframe with hue sets labels on artists\n",
        "    ax.legend(title='Country', loc='best')\n",
        "\n",
        "g.set_titles(col_template=\"{col_name}\") # Use the descriptive labels as facet titles\n",
        "g.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout to make space for the suptitle\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ojLUEV0fo8QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "\n",
        "# Create the line plot for minimum wage\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(data=df_minwage_melted, x='PERIOD', y='VALUES', hue='geo')\n",
        "\n",
        "plt.title('Minimum Wage Trends Over Time by Country (EUR/hour)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Minimum Wage (EUR/hour)')\n",
        "plt.grid(True)\n",
        "\n",
        "# Set the x-axis major locator and formatter\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(mdates.YearLocator(5)) # Show a tick every 5 years\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y')) # Format the date as YYYY\n",
        "\n",
        "# Set the x-axis limits to match the data range\n",
        "ax.set_xlim(df_minwage_melted['PERIOD'].min(), df_minwage_melted['PERIOD'].max())\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ptuLjymH3G-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# summarize VALUES per year\n",
        "df_gdp_summary = df_gdp.groupby(['geo', pd.Grouper(key='PERIOD', freq='YE')])['VALUES'].sum().reset_index()\n",
        "\n",
        "# Extract just the year for plotting for cleaner x-axis labels\n",
        "df_gdp_summary['YEAR'] = df_gdp_summary['PERIOD'].dt.year\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "ax = sns.barplot(data=df_gdp_summary, x='YEAR', y='VALUES', hue='geo', palette='Set1') # Changed palette to 'Set1'\n",
        "\n",
        "plt.title('Annual GDP Growth by Country', fontsize=16)\n",
        "plt.xlabel('Year', fontsize=12)\n",
        "plt.ylabel('Annual GDP Growth (%)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add numerical values to the bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.1f')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tXgLbqMH67V2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}